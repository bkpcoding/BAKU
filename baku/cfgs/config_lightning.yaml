defaults:
  - _self_
  - agent: baku
  - suite: droid
  - dataloader: droid
  - override hydra/launcher: submitit_local

# Root Dir
# root_dir: /home/bpatil/workspace/BAKU
root_dir: /home/bpatil/projects/BAKU
# Add data directory
data_dir: ${root_dir}/data

# misc
seed: 2
device: cuda
save_video: false
save_train_video: false
use_tb: true
# wandb logging
use_wandb: false  # enable/disable wandb logging
wandb_project: "skill_sampling"  # wandb project name
wandb_run_name: ${now:%Y.%m.%d}_${experiment}_${experiment_label}  # wandb run name
# batch_size: 512
validation_batch_size: 32
validate_every_steps: 10

# experiment
obs_type: "pixels" # pixels, features
num_demos_per_task: 50
encoder_type: 'resnet' # base, resnet
policy_type: 'gpt' # mlp, gpt
policy_head: deterministic # deterministic, gmm, bet, diffusion, vqbet
use_proprio: true
use_language: true
use_actions: false
prompt: text # text, goal, intermediate_goal
eval: false
experiment: train
experiment_label: ${policy_head}
print_actor_summary: true
# action chunking
temporal_agg: true # aggregate actions over time
num_queries: 10
load_env: false

# expert dataset
expert_dataset: ${dataloader.bc_dataset}

# Load weights
load_bc: false
bc_weight: /home/bpatil/workspace/BAKU/baku/exp_local/2025.01.22_train/vqbet/213402_hidden_dim_256/snapshot/600000.pt

# --------------- PyTorch Lightning parameters ---------------
# Multi-GPU configuration
num_gpus: ${oc.env:NUM_GPUS,1}  # Use environment variable or default to 1
# Update batch size with per-GPU and global values
per_gpu_batch_size: 512  # Set a direct value here
batch_size: ${per_gpu_batch_size}  # Initially set to per_gpu_batch_size

# Training optimization parameters
precision: 32  # 16 for mixed precision, 32 for full precision
gradient_clip_val: 1.0  # Gradient clipping value *** check if this is needed
deterministic: false  # Set to true for fully reproducible results
val_check_interval: ${validate_every_steps}  # How often to run validation

# DataLoader parameters
num_workers: 4  # DataLoader workers per GPU
pin_memory: true  # Pin memory for faster data transfer to GPU
persistent_workers: true  # Keep workers alive between epochs

# Checkpointing configuration
checkpoint_dir: "checkpoints"
save_top_k: 3  # Number of best models to save
save_last: true  # Whether to save the last model
monitor_metric: "val/actor_loss"  # Metric to monitor for best model
monitor_mode: "min"  # Direction of improvement (min or max)

# Additional logging
log_every_n_steps: ${suite.log_every_steps}  # Log frequency to match existing config

hydra:
  run:
    dir: ./exp_local/${now:%Y.%m.%d}_${experiment}/${experiment_label}/${now:%H%M%S}_hidden_dim_${suite.hidden_dim}
  sweep:
    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}
    subdir: ${hydra.job.num}
  launcher:
    tasks_per_node: 1
    nodes: 1
    submitit_folder: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${experiment}/.slurm